{"cells":[{"source":"### The data:\n\nThe dataset is collected and maintained by UCI Machine Learning Repository. The target variable is `traffic_volume`. The dataset contains the following and has already been normalized and saved into training and test sets:\n\n`train_scaled.csv`, `test_scaled.csv`\n| Column     | Type       | Description              |\n|------------|------------|--------------------------|\n|`temp`                   |Numeric            |Average temp in kelvin|\n|`rain_1h`                |Numeric            |Amount in mm of rain that occurred in the hour|\n|`snow_1h`                |Numeric            |Amount in mm of snow that occurred in the hour|\n|`clouds_all`             |Numeric            |Percentage of cloud cover|\n|`date_time`              |DateTime           |Hour of the data collected in local CST time|\n|`holiday_` (11 columns)  |Categorical        |US National holidays plus regional holiday, Minnesota State Fair|\n|`weather_main_` (11 columns)|Categorical     |Short textual description of the current weather|\n|`weather_description_` (35 columns)|Categorical|Longer textual description of the current weather|\n|`traffic_volume`         |Numeric            |Hourly I-94 ATR 301 reported westbound traffic volume|\n|`hour_of_day`|Numeric|The hour of the day|\n|`day_of_week`|Numeric|The day of the week (0=Monday, Sunday=6)|\n|`day_of_month`|Numeric|The day of the month|\n|`month`|Numeric|The number of the month|\n|`traffic_volume`         |Numeric            |Hourly I-94 ATR 301 reported westbound traffic volume|","metadata":{},"id":"8b752817-8333-446e-9790-73d85b0aa14f","cell_type":"markdown"},{"source":"1. Import Required Libraries","metadata":{},"cell_type":"markdown","id":"3f73d55b-90ae-4cd2-8587-0fae89e284a8"},{"source":"# Import the relevant libraries\nimport numpy as np\nimport pandas as pd\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import TensorDataset, DataLoader","metadata":{"executionCancelledAt":null,"executionTime":10,"lastExecutedAt":1742743011775,"lastExecutedByKernel":"7e532ae1-6c52-402f-826d-835b4ee626d6","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Import the relevant libraries\nimport numpy as np\nimport pandas as pd\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import TensorDataset, DataLoader","outputsMetadata":{"0":{"height":223,"type":"dataFrame"},"1":{"height":222,"type":"dataFrame"}}},"id":"d2e54daa-828a-420a-a204-f855de2ae375","cell_type":"code","execution_count":36,"outputs":[]},{"source":"2. Load and Prepare the Dataset","metadata":{},"cell_type":"markdown","id":"1f0d7d91-c828-41e1-8cfe-2e93149462fe"},{"source":"# Read the traffic data from the CSV training and test files\ntrain_scaled_df = pd.read_csv('train_scaled.csv')\ntest_scaled_df = pd.read_csv('test_scaled.csv')\n\n# Convert the DataFrame to NumPy arrays\ntrain_scaled = train_scaled_df.to_numpy()\ntest_scaled = test_scaled_df.to_numpy()","metadata":{"executionCancelledAt":null,"executionTime":156,"lastExecutedAt":1742743011931,"lastExecutedByKernel":"7e532ae1-6c52-402f-826d-835b4ee626d6","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Read the traffic data from the CSV training and test files\ntrain_scaled_df = pd.read_csv('train_scaled.csv')\ntest_scaled_df = pd.read_csv('test_scaled.csv')\n\n# Convert the DataFrame to NumPy arrays\ntrain_scaled = train_scaled_df.to_numpy()\ntest_scaled = test_scaled_df.to_numpy()","outputsMetadata":{"0":{"height":223,"type":"dataFrame"}}},"id":"58e3a3b9-9367-43e7-b13b-1f111447478e","cell_type":"code","execution_count":37,"outputs":[]},{"source":"3. Create Sequences from the Time Series Data","metadata":{},"cell_type":"markdown","id":"027b0ca8-b23f-4468-934c-b4609f7f77ce"},{"source":"def create_sequence(data,seq_length,target_idx):\n    inputs = []\n    targets = []\n    \n    for i in range(0, len(data) - seq_length):\n        seq_x = data[i:i+seq_length]\n        \n        seq_y = data[i+seq_length,target_idx]\n        \n        inputs.append(seq_x)\n        targets.append(seq_y)\n    return np.array(inputs), np.array(targets)","metadata":{"executionCancelledAt":null,"executionTime":52,"lastExecutedAt":1742743011985,"lastExecutedByKernel":"7e532ae1-6c52-402f-826d-835b4ee626d6","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"def create_sequence(data,seq_length,target_idx):\n    inputs = []\n    targets = []\n    \n    for i in range(0, len(data) - seq_length):\n        seq_x = data[i:i+seq_length]\n        \n        seq_y = data[i+seq_length,target_idx]\n        \n        inputs.append(seq_x)\n        targets.append(seq_y)\n    return np.array(inputs), np.array(targets)"},"id":"d29357d1-6cbb-4c86-ba49-ea31f6d8415e","cell_type":"code","execution_count":38,"outputs":[]},{"source":"4. Generate Sequences for Train and Test Sets","metadata":{},"cell_type":"markdown","id":"3f28218e-5195-4e63-bb26-05ca44332fba"},{"source":"X_train ,y_train = create_sequence(train_scaled,24,0)\nX_test ,y_test = create_sequence(test_scaled,24,0)","metadata":{"executionCancelledAt":null,"executionTime":119,"lastExecutedAt":1742743012105,"lastExecutedByKernel":"7e532ae1-6c52-402f-826d-835b4ee626d6","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"X_train ,y_train = create_sequence(train_scaled,24,0)\nX_test ,y_test = create_sequence(test_scaled,24,0)"},"cell_type":"code","id":"ba3720cc-2089-4b62-a8c2-9bb176a42f0b","outputs":[],"execution_count":39},{"source":"5. Convert NumPy Arrays to PyTorch Tensors","metadata":{},"cell_type":"markdown","id":"0b657750-67df-4924-bc8a-f95afef41f30"},{"source":"X_train_tensor = torch.tensor(X_train.astype(np.float32)).float()\ny_train_tensor = torch.tensor(y_train.astype(np.float32)).float()\nX_test_tensor = torch.tensor(X_test.astype(np.float32)).float()\ny_test_tensor = torch.tensor(y_test.astype(np.float32)).float()","metadata":{"executionCancelledAt":null,"executionTime":139,"lastExecutedAt":1742743012246,"lastExecutedByKernel":"7e532ae1-6c52-402f-826d-835b4ee626d6","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"X_train_tensor = torch.tensor(X_train.astype(np.float32)).float()\ny_train_tensor = torch.tensor(y_train.astype(np.float32)).float()\nX_test_tensor = torch.tensor(X_test.astype(np.float32)).float()\ny_test_tensor = torch.tensor(y_test.astype(np.float32)).float()"},"cell_type":"code","id":"312cef02-94e4-466f-b8c9-28154579d09c","outputs":[],"execution_count":40},{"source":"6. Wrap Tensors in TensorDataset and Load with DataLoader","metadata":{},"cell_type":"markdown","id":"2f80434b-a319-472c-a064-af548fff2378"},{"source":"# Create TensorDatasets\ntrain_dataset = TensorDataset(X_train_tensor, y_train_tensor)\ntest_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n\n# Create DataLoaders\ntrain_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)","metadata":{"executionCancelledAt":null,"executionTime":49,"lastExecutedAt":1742743012297,"lastExecutedByKernel":"7e532ae1-6c52-402f-826d-835b4ee626d6","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Create TensorDatasets\ntrain_dataset = TensorDataset(X_train_tensor, y_train_tensor)\ntest_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n\n# Create DataLoaders\ntrain_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"},"cell_type":"code","id":"c267ab06-cf97-49cf-bc21-c3b6544ae883","outputs":[],"execution_count":41},{"source":"7. Define the LSTM Neural Network Model","metadata":{},"cell_type":"markdown","id":"517aca28-f5df-4982-9b9e-3448eb1384d6"},{"source":"class TrafficModel(nn.Module):\n    def __init__(self, input_size, hidden_size=64, num_layers=2):\n        super(TrafficModel, self).__init__()\n        \n        # LSTM layer\n        self.lstm = nn.LSTM(\n            input_size=input_size,\n            hidden_size=hidden_size,\n            num_layers=num_layers,\n            batch_first=True\n        )\n        \n        # Fully connected layer\n        self.fc = nn.Linear(hidden_size, 1)\n        \n        # Activation function\n        self.activation = nn.LeakyReLU()\n    \n    def forward(self, x):\n        # x shape: (batch_size, seq_length, input_size)\n        out, (h_n, c_n) = self.lstm(x)\n        \n        # h_n shape: (num_layers, batch_size, hidden_size)\n        last_hidden = h_n[-1]  # Take the final hidden state\n        \n        out = self.fc(last_hidden)\n        out = self.activation(out)\n        \n        return out","metadata":{"executionCancelledAt":null,"executionTime":51,"lastExecutedAt":1742743012349,"lastExecutedByKernel":"7e532ae1-6c52-402f-826d-835b4ee626d6","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"class TrafficModel(nn.Module):\n    def __init__(self, input_size, hidden_size=64, num_layers=2):\n        super(TrafficModel, self).__init__()\n        \n        # LSTM layer\n        self.lstm = nn.LSTM(\n            input_size=input_size,\n            hidden_size=hidden_size,\n            num_layers=num_layers,\n            batch_first=True\n        )\n        \n        # Fully connected layer\n        self.fc = nn.Linear(hidden_size, 1)\n        \n        # Activation function\n        self.activation = nn.LeakyReLU()\n    \n    def forward(self, x):\n        # x shape: (batch_size, seq_length, input_size)\n        out, (h_n, c_n) = self.lstm(x)\n        \n        # h_n shape: (num_layers, batch_size, hidden_size)\n        last_hidden = h_n[-1]  # Take the final hidden state\n        \n        out = self.fc(last_hidden)\n        out = self.activation(out)\n        \n        return out"},"cell_type":"code","id":"c7077541-c94d-47f9-ad75-c113f20a673b","outputs":[],"execution_count":42},{"source":"8. Initialize the Model, Loss Function, and Optimizer","metadata":{},"cell_type":"markdown","id":"354a80f2-dbea-4059-92f6-dcb56334bae4"},{"source":"input_size = train_scaled.shape[1]\ntraffic_model = TrafficModel(input_size=input_size)","metadata":{"executionCancelledAt":null,"executionTime":53,"lastExecutedAt":1742743012402,"lastExecutedByKernel":"7e532ae1-6c52-402f-826d-835b4ee626d6","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"input_size = train_scaled.shape[1]\ntraffic_model = TrafficModel(input_size=input_size)"},"cell_type":"code","id":"c54e5b0e-0949-47ab-b7b7-1a98dda0f045","outputs":[],"execution_count":43},{"source":"# Loss function for regression\ncriterion = nn.MSELoss()\n\n# Optimizer (you can try Adam, SGD, etc.)\noptimizer = optim.Adam(traffic_model.parameters(), lr=0.001)","metadata":{"executionCancelledAt":null,"executionTime":54,"lastExecutedAt":1742743012457,"lastExecutedByKernel":"7e532ae1-6c52-402f-826d-835b4ee626d6","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Loss function for regression\ncriterion = nn.MSELoss()\n\n# Optimizer (you can try Adam, SGD, etc.)\noptimizer = optim.Adam(traffic_model.parameters(), lr=0.001)"},"cell_type":"code","id":"61388903-80ee-42af-8599-7018eb7dfbb6","outputs":[],"execution_count":44},{"source":"9. Train the Model","metadata":{},"cell_type":"markdown","id":"17d80e28-c4b2-4579-8a3b-134701bd7116"},{"source":"# Train for 2 epochs\nnum_epochs = 2\n\nfor epoch in range(num_epochs):\n    epoch_loss = 0.0\n\n    for X_batch, y_batch in train_loader:\n        # Reset gradients\n        optimizer.zero_grad()\n\n        # Forward pass\n        predictions = traffic_model(X_batch)\n\n        # Compute loss\n        loss = criterion(predictions.squeeze(), y_batch)\n\n        # Backward pass\n        loss.backward()\n\n        # Update weights\n        optimizer.step()\n\n        # Track the loss\n        epoch_loss += loss.item()\n\n    avg_loss = epoch_loss / len(train_loader)\n    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}\")\n\n# Store final training loss\nfinal_training_loss = avg_loss","metadata":{"executionCancelledAt":null,"executionTime":null,"lastExecutedAt":null,"lastExecutedByKernel":null,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":null,"outputsMetadata":{"0":{"height":38,"type":"stream"}}},"cell_type":"code","id":"e05fa5f1-5d98-4ae0-a491-0a033c53bad4","outputs":[],"execution_count":29},{"source":" 10. Set the Model to Evaluation Mode","metadata":{},"cell_type":"markdown","id":"e1d08a08-af97-411d-8227-02a2bf910df4"},{"source":"# Put model in evaluation mode\ntraffic_model.eval()","metadata":{"executionCancelledAt":null,"executionTime":50,"lastExecutedAt":1742743005785,"lastExecutedByKernel":"7e532ae1-6c52-402f-826d-835b4ee626d6","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Put model in evaluation mode\ntraffic_model.eval()"},"cell_type":"code","id":"b4d8ee58-f39c-4a5f-960f-6b55b4e3f695","outputs":[{"output_type":"execute_result","data":{"text/plain":"TrafficModel(\n  (lstm): LSTM(66, 64, num_layers=2, batch_first=True)\n  (fc): Linear(in_features=64, out_features=1, bias=True)\n  (activation): LeakyReLU(negative_slope=0.01)\n)"},"metadata":{},"execution_count":30}],"execution_count":30},{"source":"11. Prepare to Store Predictions and Labels","metadata":{},"cell_type":"markdown","id":"b9029a9d-5280-4e23-a4ca-636d2e5c855a"},{"source":"# Lists to store all predictions and true values\nall_preds = []\nall_labels = []","metadata":{"executionCancelledAt":null,"executionTime":52,"lastExecutedAt":1742743005837,"lastExecutedByKernel":"7e532ae1-6c52-402f-826d-835b4ee626d6","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Lists to store all predictions and true values\nall_preds = []\nall_labels = []"},"cell_type":"code","id":"adca0646-2b6c-4275-988d-76ccad1fad05","outputs":[],"execution_count":31},{"source":"12. Disable Gradient Tracking & Run Evaluation Loop","metadata":{},"cell_type":"markdown","id":"c66e7f3c-ab7f-4b69-8c38-fce80461065a"},{"source":"# Turn off gradient computation\nwith torch.no_grad():\n    for X_batch, y_batch in test_loader:\n        # Get predictions\n        outputs = traffic_model(X_batch)\n\n        # Squeeze to match shape\n        preds = outputs.squeeze()\n\n        # Store predictions and true labels\n        all_preds.append(preds)\n        all_labels.append(y_batch)","metadata":{"executionCancelledAt":null,"executionTime":5209,"lastExecutedAt":1742743011046,"lastExecutedByKernel":"7e532ae1-6c52-402f-826d-835b4ee626d6","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Turn off gradient computation\nwith torch.no_grad():\n    for X_batch, y_batch in test_loader:\n        # Get predictions\n        outputs = traffic_model(X_batch)\n\n        # Squeeze to match shape\n        preds = outputs.squeeze()\n\n        # Store predictions and true labels\n        all_preds.append(preds)\n        all_labels.append(y_batch)"},"cell_type":"code","id":"8da75625-f475-4c97-adb1-c54d3a3796b6","outputs":[],"execution_count":32},{"source":"13. Concatenate All Batches Into Full Prediction Tensors","metadata":{},"cell_type":"markdown","id":"773a075d-7587-4f8c-ac2f-e98c6c152885"},{"source":"# Concatenate all predictions and labels into full tensors\nall_preds_tensor = torch.cat(all_preds)\nall_labels_tensor = torch.cat(all_labels)","metadata":{"executionCancelledAt":null,"executionTime":49,"lastExecutedAt":1742743011097,"lastExecutedByKernel":"7e532ae1-6c52-402f-826d-835b4ee626d6","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Concatenate all predictions and labels into full tensors\nall_preds_tensor = torch.cat(all_preds)\nall_labels_tensor = torch.cat(all_labels)"},"cell_type":"code","id":"1a0f0488-1c23-43b8-9805-a1f6e9508046","outputs":[],"execution_count":33},{"source":"14. Compute Mean Squared Error on Test Set","metadata":{},"cell_type":"markdown","id":"51361e70-c12b-4317-b5f6-ad5bbe07de8e"},{"source":"# Compute Mean Squared Error over the entire test set\ntest_mse = F.mse_loss(all_preds_tensor, all_labels_tensor)\n\nprint(f\"Test MSE: {test_mse.item():.4f}\")","metadata":{"executionCancelledAt":null,"executionTime":48,"lastExecutedAt":1742743011145,"lastExecutedByKernel":"7e532ae1-6c52-402f-826d-835b4ee626d6","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Compute Mean Squared Error over the entire test set\ntest_mse = F.mse_loss(all_preds_tensor, all_labels_tensor)\n\nprint(f\"Test MSE: {test_mse.item():.4f}\")","outputsMetadata":{"0":{"height":38,"type":"stream"}}},"cell_type":"code","id":"dfee0a91-47b8-475c-95de-18469f3fc4fd","outputs":[{"output_type":"stream","name":"stdout","text":"Test MSE: 0.0002\n"}],"execution_count":34}],"metadata":{"colab":{"name":"Welcome to DataCamp Workspaces.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.8.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"editor":"DataLab"},"nbformat":4,"nbformat_minor":5}